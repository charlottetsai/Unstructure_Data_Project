{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'housing.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1379c33cb482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'housing.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m         )\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m             )\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'housing.csv'"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('housing.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>type</th>\n",
       "      <th>sqfeet</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>cats_allowed</th>\n",
       "      <th>...</th>\n",
       "      <th>wheelchair_access</th>\n",
       "      <th>electric_vehicle_charge</th>\n",
       "      <th>comes_furnished</th>\n",
       "      <th>laundry_options</th>\n",
       "      <th>parking_options</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7049044568</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-beautif...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1148</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1078</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d in unit</td>\n",
       "      <td>carport</td>\n",
       "      <td>https://images.craigslist.org/01616_daghmBUvTC...</td>\n",
       "      <td>Ridgeview by Vintage is where you will find al...</td>\n",
       "      <td>39.5483</td>\n",
       "      <td>-119.796</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7049047186</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-reduced...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1200</td>\n",
       "      <td>condo</td>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d hookups</td>\n",
       "      <td>carport</td>\n",
       "      <td>https://images.craigslist.org/00V0V_5va0MkgO9q...</td>\n",
       "      <td>Conveniently located in the middle town of Ren...</td>\n",
       "      <td>39.5026</td>\n",
       "      <td>-119.789</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7043634882</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/sparks-state...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1813</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1683</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d in unit</td>\n",
       "      <td>attached garage</td>\n",
       "      <td>https://images.craigslist.org/00t0t_erYqC6LgB8...</td>\n",
       "      <td>2BD | 2BA | 1683SQFTDiscover exceptional servi...</td>\n",
       "      <td>39.6269</td>\n",
       "      <td>-119.708</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7049045324</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-1x1-fir...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1095</td>\n",
       "      <td>apartment</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d in unit</td>\n",
       "      <td>carport</td>\n",
       "      <td>https://images.craigslist.org/00303_3HSJz75zlI...</td>\n",
       "      <td>MOVE IN SPECIAL FREE WASHER/DRYER WITH 6 OR 12...</td>\n",
       "      <td>39.4477</td>\n",
       "      <td>-119.771</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7049043759</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-no-long...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>289</td>\n",
       "      <td>apartment</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>laundry on site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://images.craigslist.org/01616_fALAWFV8zQ...</td>\n",
       "      <td>Move In Today: Reno Low-Cost, Clean &amp; Furnishe...</td>\n",
       "      <td>39.5357</td>\n",
       "      <td>-119.805</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                                url  \\\n",
       "0  7049044568  https://reno.craigslist.org/apa/d/reno-beautif...   \n",
       "1  7049047186  https://reno.craigslist.org/apa/d/reno-reduced...   \n",
       "2  7043634882  https://reno.craigslist.org/apa/d/sparks-state...   \n",
       "3  7049045324  https://reno.craigslist.org/apa/d/reno-1x1-fir...   \n",
       "4  7049043759  https://reno.craigslist.org/apa/d/reno-no-long...   \n",
       "\n",
       "         region                   region_url  price       type  sqfeet  beds  \\\n",
       "0  reno / tahoe  https://reno.craigslist.org   1148  apartment    1078     3   \n",
       "1  reno / tahoe  https://reno.craigslist.org   1200      condo    1001     2   \n",
       "2  reno / tahoe  https://reno.craigslist.org   1813  apartment    1683     2   \n",
       "3  reno / tahoe  https://reno.craigslist.org   1095  apartment     708     1   \n",
       "4  reno / tahoe  https://reno.craigslist.org    289  apartment     250     0   \n",
       "\n",
       "   baths  cats_allowed  ...  wheelchair_access  electric_vehicle_charge  \\\n",
       "0    2.0             1  ...                  0                        0   \n",
       "1    2.0             0  ...                  0                        0   \n",
       "2    2.0             1  ...                  0                        0   \n",
       "3    1.0             1  ...                  0                        0   \n",
       "4    1.0             1  ...                  1                        0   \n",
       "\n",
       "   comes_furnished  laundry_options  parking_options  \\\n",
       "0                0      w/d in unit          carport   \n",
       "1                0      w/d hookups          carport   \n",
       "2                0      w/d in unit  attached garage   \n",
       "3                0      w/d in unit          carport   \n",
       "4                1  laundry on site              NaN   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.craigslist.org/01616_daghmBUvTC...   \n",
       "1  https://images.craigslist.org/00V0V_5va0MkgO9q...   \n",
       "2  https://images.craigslist.org/00t0t_erYqC6LgB8...   \n",
       "3  https://images.craigslist.org/00303_3HSJz75zlI...   \n",
       "4  https://images.craigslist.org/01616_fALAWFV8zQ...   \n",
       "\n",
       "                                         description      lat     long  state  \n",
       "0  Ridgeview by Vintage is where you will find al...  39.5483 -119.796     ca  \n",
       "1  Conveniently located in the middle town of Ren...  39.5026 -119.789     ca  \n",
       "2  2BD | 2BA | 1683SQFTDiscover exceptional servi...  39.6269 -119.708     ca  \n",
       "3  MOVE IN SPECIAL FREE WASHER/DRYER WITH 6 OR 12...  39.4477 -119.771     ca  \n",
       "4  Move In Today: Reno Low-Cost, Clean & Furnishe...  39.5357 -119.805     ca  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apartment          318032\n",
       "house               33266\n",
       "townhouse           15885\n",
       "condo                6238\n",
       "duplex               5047\n",
       "manufactured         4242\n",
       "cottage/cabin         861\n",
       "loft                  693\n",
       "flat                  531\n",
       "in-law                172\n",
       "land                    8\n",
       "assisted living         2\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[data_df.type != 'manufactured']\n",
    "data_df = data_df[data_df.type != 'in-law']\n",
    "data_df = data_df[data_df.type != 'land']\n",
    "data_df = data_df[data_df.type != 'assisted living']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apartment        318032\n",
       "house             33266\n",
       "townhouse         15885\n",
       "condo              6238\n",
       "duplex             5047\n",
       "cottage/cabin       861\n",
       "loft                693\n",
       "flat                531\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['type'] = data_df['type'].replace(['condo','loft','flat',],'apartment')\n",
    "data_df['type'] = data_df['type'].replace(['townhouse','duplex','cottage/cabin'],'house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apartment    325494\n",
       "house         55059\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ishouse(row):\n",
    "    if row['type'] == 'house':\n",
    "        return int(1)\n",
    "    else:\n",
    "        return int(0)\n",
    "\n",
    "\n",
    "data_df['Is_House']= data_df.apply(lambda k : ishouse(k),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>region</th>\n",
       "      <th>region_url</th>\n",
       "      <th>price</th>\n",
       "      <th>type</th>\n",
       "      <th>sqfeet</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>cats_allowed</th>\n",
       "      <th>...</th>\n",
       "      <th>electric_vehicle_charge</th>\n",
       "      <th>comes_furnished</th>\n",
       "      <th>laundry_options</th>\n",
       "      <th>parking_options</th>\n",
       "      <th>image_url</th>\n",
       "      <th>description</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>state</th>\n",
       "      <th>Is_House</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7049044568</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-beautif...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1148</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1078</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d in unit</td>\n",
       "      <td>carport</td>\n",
       "      <td>https://images.craigslist.org/01616_daghmBUvTC...</td>\n",
       "      <td>Ridgeview by Vintage is where you will find al...</td>\n",
       "      <td>39.5483</td>\n",
       "      <td>-119.796</td>\n",
       "      <td>ca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7049047186</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-reduced...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1200</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1001</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d hookups</td>\n",
       "      <td>carport</td>\n",
       "      <td>https://images.craigslist.org/00V0V_5va0MkgO9q...</td>\n",
       "      <td>Conveniently located in the middle town of Ren...</td>\n",
       "      <td>39.5026</td>\n",
       "      <td>-119.789</td>\n",
       "      <td>ca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7043634882</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/sparks-state...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1813</td>\n",
       "      <td>apartment</td>\n",
       "      <td>1683</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d in unit</td>\n",
       "      <td>attached garage</td>\n",
       "      <td>https://images.craigslist.org/00t0t_erYqC6LgB8...</td>\n",
       "      <td>2BD | 2BA | 1683SQFTDiscover exceptional servi...</td>\n",
       "      <td>39.6269</td>\n",
       "      <td>-119.708</td>\n",
       "      <td>ca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7049045324</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-1x1-fir...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>1095</td>\n",
       "      <td>apartment</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w/d in unit</td>\n",
       "      <td>carport</td>\n",
       "      <td>https://images.craigslist.org/00303_3HSJz75zlI...</td>\n",
       "      <td>MOVE IN SPECIAL FREE WASHER/DRYER WITH 6 OR 12...</td>\n",
       "      <td>39.4477</td>\n",
       "      <td>-119.771</td>\n",
       "      <td>ca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7049043759</td>\n",
       "      <td>https://reno.craigslist.org/apa/d/reno-no-long...</td>\n",
       "      <td>reno / tahoe</td>\n",
       "      <td>https://reno.craigslist.org</td>\n",
       "      <td>289</td>\n",
       "      <td>apartment</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>laundry on site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://images.craigslist.org/01616_fALAWFV8zQ...</td>\n",
       "      <td>Move In Today: Reno Low-Cost, Clean &amp; Furnishe...</td>\n",
       "      <td>39.5357</td>\n",
       "      <td>-119.805</td>\n",
       "      <td>ca</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                                url  \\\n",
       "0  7049044568  https://reno.craigslist.org/apa/d/reno-beautif...   \n",
       "1  7049047186  https://reno.craigslist.org/apa/d/reno-reduced...   \n",
       "2  7043634882  https://reno.craigslist.org/apa/d/sparks-state...   \n",
       "3  7049045324  https://reno.craigslist.org/apa/d/reno-1x1-fir...   \n",
       "4  7049043759  https://reno.craigslist.org/apa/d/reno-no-long...   \n",
       "\n",
       "         region                   region_url  price       type  sqfeet  beds  \\\n",
       "0  reno / tahoe  https://reno.craigslist.org   1148  apartment    1078     3   \n",
       "1  reno / tahoe  https://reno.craigslist.org   1200  apartment    1001     2   \n",
       "2  reno / tahoe  https://reno.craigslist.org   1813  apartment    1683     2   \n",
       "3  reno / tahoe  https://reno.craigslist.org   1095  apartment     708     1   \n",
       "4  reno / tahoe  https://reno.craigslist.org    289  apartment     250     0   \n",
       "\n",
       "   baths  cats_allowed  ...  electric_vehicle_charge  comes_furnished  \\\n",
       "0    2.0             1  ...                        0                0   \n",
       "1    2.0             0  ...                        0                0   \n",
       "2    2.0             1  ...                        0                0   \n",
       "3    1.0             1  ...                        0                0   \n",
       "4    1.0             1  ...                        0                1   \n",
       "\n",
       "   laundry_options  parking_options  \\\n",
       "0      w/d in unit          carport   \n",
       "1      w/d hookups          carport   \n",
       "2      w/d in unit  attached garage   \n",
       "3      w/d in unit          carport   \n",
       "4  laundry on site              NaN   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.craigslist.org/01616_daghmBUvTC...   \n",
       "1  https://images.craigslist.org/00V0V_5va0MkgO9q...   \n",
       "2  https://images.craigslist.org/00t0t_erYqC6LgB8...   \n",
       "3  https://images.craigslist.org/00303_3HSJz75zlI...   \n",
       "4  https://images.craigslist.org/01616_fALAWFV8zQ...   \n",
       "\n",
       "                                         description      lat     long state  \\\n",
       "0  Ridgeview by Vintage is where you will find al...  39.5483 -119.796    ca   \n",
       "1  Conveniently located in the middle town of Ren...  39.5026 -119.789    ca   \n",
       "2  2BD | 2BA | 1683SQFTDiscover exceptional servi...  39.6269 -119.708    ca   \n",
       "3  MOVE IN SPECIAL FREE WASHER/DRYER WITH 6 OR 12...  39.4477 -119.771    ca   \n",
       "4  Move In Today: Reno Low-Cost, Clean & Furnishe...  39.5357 -119.805    ca   \n",
       "\n",
       "   Is_House  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['weights'] = np.where(data_df['Is_House'] == 1, 0.15, 0.85)\n",
    "sample_df = data_df.sample(frac=.2, random_state=111, weights='weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           int64\n",
       "url                         object\n",
       "region                      object\n",
       "region_url                  object\n",
       "price                        int64\n",
       "type                        object\n",
       "sqfeet                       int64\n",
       "beds                         int64\n",
       "baths                      float64\n",
       "cats_allowed                 int64\n",
       "dogs_allowed                 int64\n",
       "smoking_allowed              int64\n",
       "wheelchair_access            int64\n",
       "electric_vehicle_charge      int64\n",
       "comes_furnished              int64\n",
       "laundry_options             object\n",
       "parking_options             object\n",
       "image_url                   object\n",
       "description                 object\n",
       "lat                        float64\n",
       "long                       float64\n",
       "state                       object\n",
       "Is_House                     int64\n",
       "weights                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(sample_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'url', 'region', 'region_url', 'price', 'type', 'sqfeet', 'beds',\n",
       "       'baths', 'cats_allowed', 'dogs_allowed', 'smoking_allowed',\n",
       "       'wheelchair_access', 'electric_vehicle_charge', 'comes_furnished',\n",
       "       'laundry_options', 'parking_options', 'image_url', 'description', 'lat',\n",
       "       'long', 'state', 'Is_House', 'weights'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "count_vectorizer = CountVectorizer(binary=True)\n",
    "tfidf_vector = TfidfVectorizer(ngram_range=(1,3), stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the lists for TRAINING DATA \n",
    "train_token_x = []\n",
    "\n",
    "# Running the loop to tokenize, lemmatize, and remove the stop words from the reviews\n",
    "for idx,row in data_train.iterrows():\n",
    "    token_text = word_tokenize(str(row['description']).lower())\n",
    "    lemmatized_text = [lemmatizer.lemmatize(token) for token in token_text if token.isalpha()]\n",
    "    text_remove_stopwords = [token for token in lemmatized_text if not token in stopwords.words('english') if token.isalpha()]\n",
    "    token1 = ''\n",
    "    for token in text_remove_stopwords:\n",
    "        token1 = token1 + ' ' + token\n",
    "    train_token_x.append(token1)\n",
    "\n",
    "\n",
    "tfidf_vector.fit(train_token_x)\n",
    "train_tfidf_x = tfidf_vector.fit_transform(train_token_x)\n",
    "\n",
    "train_y = data_train.Is_House\n",
    "\n",
    "# Initializing the lists for TESTING DATA \n",
    "test_token_x = []\n",
    "\n",
    "for idx,row in data_test.iterrows():\n",
    "    token_text = word_tokenize(str(row['description']).lower())\n",
    "    lemmatized_text = [lemmatizer.lemmatize(token) for token in token_text if token.isalpha()]\n",
    "    text_remove_stopwords = [token for token in lemmatized_text if not token in stopwords.words('english') if token.isalpha()]\n",
    "    token2 = ''\n",
    "    for token in text_remove_stopwords:\n",
    "        token2 = token2 + ' ' + token\n",
    "    test_token_x.append(token2)\n",
    "\n",
    "\n",
    "test_tfidf_x = tfidf_vector.transform(test_token_x)\n",
    "\n",
    "test_y = data_test.Is_House\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60888, 2097232), (60888,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15223, 2097232), (15223,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy for Logistic Regression is: 96.91256651120015 %\n",
      "The prediction accuracy for Random Forest is: 97.01767062996781 %\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "logistic_regression = LogisticRegression(random_state=10)\n",
    "logi_regr = logistic_regression.fit(train_tfidf_x, train_y)\n",
    "logi_predicted_y = logi_regr.predict(test_tfidf_x)\n",
    "print(\"The prediction accuracy for Logistic Regression is:\", np.mean(logi_predicted_y == test_y)*100, \"%\")\n",
    "\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(n_estimators = 100, random_state=10)\n",
    "model_rf = random_forest.fit(train_tfidf_x, train_y)\n",
    "rf_predicted_y = model_rf.predict(test_tfidf_x)\n",
    "print(\"The prediction accuracy for Random Forest is:\", np.mean(rf_predicted_y == test_y)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/harishgavva/Desktop/BAIM/Mod-4/Unstructured/Project-Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c815c3c61e57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Predicting for actual data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mact_data_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/harishgavva/Desktop/BAIM/Mod-4/Unstructured/Project-Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# List for Actual Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1369\u001b[0m         )\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m             )\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/harishgavva/Desktop/BAIM/Mod-4/Unstructured/Project-Data.csv'"
     ]
    }
   ],
   "source": [
    "#Predicting for actual data\n",
    "\n",
    "act_data_df = pd.read_csv('/Users/harishgavva/Desktop/BAIM/Mod-4/Unstructured/Project-Data.csv')\n",
    "\n",
    "# List for Actual Data \n",
    "act_token_x = []\n",
    "\n",
    "for idx,row in act_data_df.iterrows():\n",
    "    token_text = word_tokenize(str(row['Description']).lower())\n",
    "    lemmatized_text = [lemmatizer.lemmatize(token) for token in token_text if token.isalpha()]\n",
    "    text_remove_stopwords = [token for token in lemmatized_text if not token in stopwords.words('english') if token.isalpha()]\n",
    "    token3 = ''\n",
    "    for token in text_remove_stopwords:\n",
    "        token3 = token3 + ' ' + token\n",
    "    act_token_x.append(token3)\n",
    "\n",
    "act_tfidf_x = tfidf_vector.transform(act_token_x)\n",
    "\n",
    "predicted_y_act = model_rf.predict_proba(act_tfidf_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_act_df = pd.DataFrame(predicted_y_act,columns = ['is_house'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def housetype(row):\n",
    "    if row['is_house'] == 1:\n",
    "        return 'house'\n",
    "    else:\n",
    "        return 'apartment'\n",
    "pred_y_act_df['type'] = pred_y_act_df.apply(lambda k :housetype(k),axis=1)\n",
    "\n",
    "pred_y_act_df.is_house.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Part 2. Topic Model\n",
    "\n",
    "## 1. Transform those reviews into a term-document matrix, lemmatize all the words, remove the stop-words and\n",
    "# punctuations, set the minimal document frequency for each term to be 5 and include uni-gram and bi-gram.\n",
    "# Load the file\n",
    "assignment_file = open('/Users/harishgavva/Desktop/BAIM/Mod-4/Unstructured/Project-Data.csv',encoding=\"utf-8\")\n",
    "assignment_reader = csv.reader(assignment_file)\n",
    "review_data = list(assignment_reader)\n",
    "\n",
    "review_list = []\n",
    "for review in review_data:\n",
    "    review_list.append(review[4])\n",
    "\n",
    "\n",
    "# Tokenization and lemmatization\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if t.isalpha()]\n",
    "\n",
    "\n",
    "# Remove Stopwords and punctuation directly in Countvectorizer\n",
    "my_stop_words = [t for t in (set(stopwords.words('english'))-set(['not','no','dont']))]\n",
    "\n",
    "self_defined_stop_words = ['wa', 'quot', 'ha', 'gt', 'also','contact','contact info','home',\n",
    "                           'community','info','show','show info','today','call','de','la','en','el','para',\n",
    "                           'con','de la','un','available','â','â â','u','ri','http','hour','feature','offer',\n",
    "                           'del','los','una','se','por','que','located','one','indianapolis','apartment','qr code',\n",
    "                           'life','live','code','link','qr',\"gene\", \"glick\"] # These are extra stop words I defined after running the topics many times\n",
    "my_stop_words.extend(self_defined_stop_words)\n",
    "vectorizer = TfidfVectorizer(stop_words=my_stop_words, tokenizer=LemmaTokenizer(), encoding='utf-8', min_df=10,\n",
    "                             ngram_range=(2, 3))\n",
    "review_vect = vectorizer.fit_transform(review_list)\n",
    "\n",
    "# 2. Use the LDA model to extract the topics of each document assuming there are 6 topics.\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "terms = vectorizer.get_feature_names()\n",
    "lda = LatentDirichletAllocation(n_components=6, random_state=0).fit(review_vect)\n",
    "doc_topic = lda.transform(review_vect)  # 1000 by 6\n",
    "term_document_matrix = doc_topic.transpose()  # 6 by 1000\n",
    "\n",
    "\n",
    "# 4. Find the top-5 terms (terms with the top-5 highest weights) for each of the 6 topics.\n",
    "# Based on those terms, describe what those topics are about.\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic %d:\" % (topic_idx))\n",
    "    print(\", \".join([terms[i] for i in topic.argsort()[:-15 - 1:-1]]))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic 0: Windsor park\n",
    "\n",
    "\n",
    "Topic 1: Abney Lake\n",
    "\n",
    "\n",
    "Topic 2: Airport\n",
    "\n",
    "\n",
    "Topic 3: Busline\n",
    "\n",
    "\n",
    "Topic 4: Prime Location\n",
    "\n",
    "\n",
    "Topic 5: Lighthouse Landing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "project_data_df = pd.read_csv('/Users/harishgavva/Desktop/BAIM/Mod-4/Unstructured/Project-Data.csv')\n",
    "\n",
    "topic_df = pd.DataFrame(doc_topic,columns=['Windsor Park','Abney Lake','Near Airport','Near Busline','Prime Location','Lighthouse Landing'])\n",
    "\n",
    "topic_df['Tag'] = topic_df.idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([project_data_df,topic_df['Tag']],axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
